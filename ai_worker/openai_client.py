import os
from dotenv import load_dotenv
from openai import OpenAI
from logger import get_logger
logger = get_logger(__name__)

def ask_gpt(prompt: str, model: str = "mistralai/Mistral-7B-Instruct-v0.2", temperature: float = 0.7):
    logger.info(f"ðŸ¤– ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº Ð˜Ð˜: {prompt}")
    try:
        # Ð¢Ð²Ð¾Ð¹ Ð²Ñ‹Ð·Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ‚ÑƒÑ‚:
        response = {
            "choices": [{
                "message": {
                    "content": "ðŸ”§ Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ°: Ð˜Ð˜ Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚"
                }
            }]
        }
        logger.debug(f"ðŸ“¥ ÐžÑ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {response}")
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        logger.exception("ðŸ’¥ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ð¸ Ðº Together.ai")
        return "âš ï¸ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ð¸ Ðº Ð˜Ð˜"

load_dotenv()

client = OpenAI(
    api_key=os.getenv("TOGETHER_API_KEY"),
    base_url="https://api.together.xyz/v1"
)

def ask_gpt(prompt: str, model: str = "mistralai/Mistral-7B-Instruct-v0.2", temperature: float = 0.7) -> str:
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Ð¢Ñ‹ â€” AI-Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¿Ð¾ Ñ‚ÐµÐ½Ð´ÐµÑ€Ð°Ð¼. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ."},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ðŸ›‘ ÐžÑˆÐ¸Ð±ÐºÐ° Together.ai: {e}"
